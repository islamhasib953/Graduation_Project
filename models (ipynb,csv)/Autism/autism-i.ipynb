{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff7b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import joblib\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fcde03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23810710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
      "0        1   0   0   0   0   0   0   1   1   0    1        28               3   \n",
      "1        2   1   1   0   0   0   1   1   0   0    0        36               4   \n",
      "2        3   1   0   0   0   0   0   1   1   0    1        36               4   \n",
      "3        4   1   1   1   1   1   1   1   1   1    1        24              10   \n",
      "4        5   1   1   0   1   1   1   1   1   1    1        20               9   \n",
      "\n",
      "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
      "0   f  middle eastern      yes                  no          family member   \n",
      "1   m  White European      yes                  no          family member   \n",
      "2   m  middle eastern      yes                  no          family member   \n",
      "3   m        Hispanic       no                  no          family member   \n",
      "4   f  White European       no                 yes          family member   \n",
      "\n",
      "  Class/ASD Traits   \n",
      "0                No  \n",
      "1               Yes  \n",
      "2               Yes  \n",
      "3               Yes  \n",
      "4               Yes  \n",
      "Case_No                   0\n",
      "A1                        0\n",
      "A2                        0\n",
      "A3                        0\n",
      "A4                        0\n",
      "A5                        0\n",
      "A6                        0\n",
      "A7                        0\n",
      "A8                        0\n",
      "A9                        0\n",
      "A10                       0\n",
      "Age_Mons                  0\n",
      "Qchat-10-Score            0\n",
      "Sex                       0\n",
      "Ethnicity                 0\n",
      "Jaundice                  0\n",
      "Family_mem_with_ASD       0\n",
      "Who completed the test    0\n",
      "Class/ASD Traits          0\n",
      "dtype: int64\n",
      "   Case_No  A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons  Qchat-10-Score  \\\n",
      "0        1   0   0   0   0   0   0   1   1   0    1         2               3   \n",
      "1        2   1   1   0   0   0   1   1   0   0    0         3               4   \n",
      "2        3   1   0   0   0   0   0   1   1   0    1         3               4   \n",
      "3        4   1   1   1   1   1   1   1   1   1    1         2              10   \n",
      "4        5   1   1   0   1   1   1   1   1   1    1         1               9   \n",
      "\n",
      "  Sex       Ethnicity Jaundice Family_mem_with_ASD Who completed the test  \\\n",
      "0   f  middle eastern      yes                  no          family member   \n",
      "1   m  White European      yes                  no          family member   \n",
      "2   m  middle eastern      yes                  no          family member   \n",
      "3   m        Hispanic       no                  no          family member   \n",
      "4   f  White European       no                 yes          family member   \n",
      "\n",
      "  Class/ASD Traits   \n",
      "0                No  \n",
      "1               Yes  \n",
      "2               Yes  \n",
      "3               Yes  \n",
      "4               Yes  \n",
      "   A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  Age_Mons Sex       Ethnicity  \\\n",
      "0   0   0   0   0   0   0   1   1   0    1         2   f  middle eastern   \n",
      "1   1   1   0   0   0   1   1   0   0    0         3   m  White European   \n",
      "2   1   0   0   0   0   0   1   1   0    1         3   m  middle eastern   \n",
      "3   1   1   1   1   1   1   1   1   1    1         2   m        Hispanic   \n",
      "4   1   1   0   1   1   1   1   1   1    1         1   f  White European   \n",
      "\n",
      "  Jaundice Family_mem_with_ASD Who completed the test Class/ASD Traits   \n",
      "0      yes                  no          family member                No  \n",
      "1      yes                  no          family member               Yes  \n",
      "2      yes                  no          family member               Yes  \n",
      "3       no                  no          family member               Yes  \n",
      "4       no                 yes          family member               Yes  \n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing Phase\n",
    "pd.set_option('display.max_columns', None)\n",
    "d1 = pd.read_csv(\"Toddler Autism dataset July 2018.csv\")\n",
    "print(d1.head())\n",
    "\n",
    "print(d1.isna().sum())\n",
    "\n",
    "# Convert Age_Mons to years\n",
    "d1[\"Age_Mons\"] = (d1[\"Age_Mons\"]/12).astype(int)\n",
    "print(d1.head())\n",
    "\n",
    "# Drop Case_No and Qchat-10-Score\n",
    "d1 = d1.drop([\"Case_No\", \"Qchat-10-Score\"], axis=1)\n",
    "print(d1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ead65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded column Sex: {'f': 0, 'm': 1}\n",
      "Encoded column Ethnicity: {'Hispanic': 0, 'Latino': 1, 'Native Indian': 2, 'Others': 3, 'Pacifica': 4, 'White European': 5, 'asian': 6, 'black': 7, 'middle eastern': 8, 'mixed': 9, 'south asian': 10}\n",
      "Encoded column Jaundice: {'no': 0, 'yes': 1}\n",
      "Encoded column Family_mem_with_ASD: {'no': 0, 'yes': 1}\n",
      "Encoded column Who completed the test: {'Health Care Professional': 0, 'Health care professional': 1, 'Others': 2, 'Self': 3, 'family member': 4}\n",
      "Encoded column Class/ASD Traits : {'No': 0, 'Yes': 1}\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical columns using LabelEncoder\n",
    "categorical_cols = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test', 'Class/ASD Traits ']\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    d1[col] = le.fit_transform(d1[col]).astype(np.int8)\n",
    "    le_dict[col] = le\n",
    "    print(f\"Encoded column {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ee4bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved LabelEncoder mappings to models/autism/label_encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save LabelEncoder mappings\n",
    "joblib.dump(le_dict, 'autism_label_encoders.pkl')\n",
    "logger.info(\"Saved LabelEncoder mappings to models/autism/label_encoders.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25b4f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Features: ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test']\n",
      "INFO:__main__:Applied StandardScaler to features\n"
     ]
    }
   ],
   "source": [
    "# Split features and target\n",
    "X = d1.drop(\"Class/ASD Traits \", axis=1)\n",
    "y = d1[\"Class/ASD Traits \"]\n",
    "logger.info(f\"Features: {X.columns.tolist()}\")\n",
    "\n",
    "# Initialize StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "logger.info(\"Applied StandardScaler to features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581c0546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved scaler to autism_scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save scaler\n",
    "scaler_filename = 'autism_scaler.pkl'\n",
    "joblib.dump(sc, scaler_filename)\n",
    "logger.info(f\"Saved scaler to {scaler_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa4a799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Split data into 80% train and 20% test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Confusion Matrix is: \n",
      "[[ 61   4]\n",
      " [  4 142]]\n",
      "\n",
      "\n",
      "Score Table is: \n",
      "RandomForest 5-Fold CV F1 Scores: [0.9787234  0.97413793 0.96610169 0.95726496 0.98712446]\n",
      "RandomForest Mean CV F1: 0.9727 (+/- 0.0206)\n",
      "              accuracy  precision    recall        f1   roc_auc\n",
      "RandomForest  0.962085   0.972603  0.972603  0.972603  0.993572\n"
     ]
    }
   ],
   "source": [
    "# Split the scaled data into train and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=69, stratify=y\n",
    ")\n",
    "logger.info(\"Split data into 80% train and 20% test\")\n",
    "\n",
    "# Define training and evaluation function\n",
    "def train_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix is: \")\n",
    "    print(matrix)\n",
    "    print(\"\\n\\nScore Table is: \")\n",
    "    score_df = pd.DataFrame([[accuracy, precision, recall, f1, roc_auc]], \n",
    "                            columns=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"])\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    print(f\"{model_name} 5-Fold CV F1 Scores: {cv_scores}\")\n",
    "    print(f\"{model_name} Mean CV F1: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    \n",
    "    return score_df\n",
    "\n",
    "# Train and tune RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=69, class_weight='balanced')\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "print(f\"Best RandomForest parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate RandomForest\n",
    "rf_result = train_model(best_rf, X_train, y_train, X_test, y_test, \"RandomForest\")\n",
    "rf_result.index = [\"RandomForest\"]\n",
    "print(rf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d688834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix is: \n",
      "[[ 65   0]\n",
      " [  0 146]]\n",
      "\n",
      "\n",
      "Score Table is: \n",
      "LogisticRegression 5-Fold CV F1 Scores: [1. 1. 1. 1. 1.]\n",
      "LogisticRegression Mean CV F1: 1.0000 (+/- 0.0000)\n",
      "                    accuracy  precision  recall   f1  roc_auc\n",
      "LogisticRegression       1.0        1.0     1.0  1.0      1.0\n",
      "\n",
      "Model Comparison:\n",
      "\n",
      "                    accuracy  precision    recall        f1   roc_auc\n",
      "RandomForest        0.962085   0.972603  0.972603  0.972603  0.993572\n",
      "LogisticRegression  1.000000   1.000000  1.000000  1.000000  1.000000\n",
      "Model saved to autism_rf_model.pkl\n",
      "\n",
      "Feature Importance:\n",
      "\n",
      "                   Feature  Importance\n",
      "8                       A9    0.188722\n",
      "4                       A5    0.159678\n",
      "5                       A6    0.110346\n",
      "6                       A7    0.099607\n",
      "0                       A1    0.092827\n",
      "1                       A2    0.081727\n",
      "3                       A4    0.067003\n",
      "7                       A8    0.047977\n",
      "12               Ethnicity    0.038654\n",
      "2                       A3    0.031895\n",
      "9                      A10    0.024093\n",
      "10                Age_Mons    0.022208\n",
      "13                Jaundice    0.014724\n",
      "11                     Sex    0.010755\n",
      "14     Family_mem_with_ASD    0.007751\n",
      "15  Who completed the test    0.002034\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate LogisticRegression as a backup\n",
    "lr = LogisticRegression(max_iter=2000, class_weight='balanced', random_state=69)\n",
    "lr_result = train_model(lr, X_train, y_train, X_test, y_test, \"LogisticRegression\")\n",
    "lr_result.index = [\"LogisticRegression\"]\n",
    "print(lr_result)\n",
    "\n",
    "# Combine results\n",
    "results = pd.concat([rf_result, lr_result])\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "print(results)\n",
    "\n",
    "#Save the best model (RandomForest)\n",
    "model_filename = 'autism_rf_model.pkl'\n",
    "joblib.dump(best_rf, model_filename)\n",
    "print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "# Save LogisticRegression as a backup\n",
    "# backup_model_filename = 'models/autism/autism_lr_model.pkl'\n",
    "# joblib.dump(lr, backup_model_filename)\n",
    "# print(f\"Saved LogisticRegression model to {backup_model_filename}\")\n",
    "\n",
    "# Feature importance (for RandomForest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a42a8fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, random_state=69)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=10, random_state=69)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10, random_state=69)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d69b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded LabelEncoder mappings, scaler, and RandomForest model\n",
      "INFO:__main__:Prediction completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Probabilities:\n",
      "   No Autism (Prob)  Autism (Prob)\n",
      "0           0.99971        0.00029\n"
     ]
    }
   ],
   "source": [
    "# Load LabelEncoder mappings, scaler, and model\n",
    "try:\n",
    "    le_dict = joblib.load('autism_label_encoders.pkl')\n",
    "    scaler = joblib.load('autism_scaler.pkl')\n",
    "    best_rf = joblib.load('autism_rf_model.pkl')\n",
    "    logger.info(\"Loaded LabelEncoder mappings, scaler, and RandomForest model\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Error loading files: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Define function to preprocess input data\n",
    "def preprocess_input(input_data, le_dict, scaler):\n",
    "    # Convert input to DataFrame if it's a dictionary\n",
    "    if isinstance(input_data, dict):\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "    else:\n",
    "        input_df = input_data.copy()\n",
    "\n",
    "    # Convert Age_Mons to years\n",
    "    if 'Age_Mons' in input_df.columns:\n",
    "        input_df['Age_Mons'] = (input_df['Age_Mons'] / 12).astype(int)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test']\n",
    "    for col in categorical_cols:\n",
    "        if col in input_df.columns:\n",
    "            le = le_dict[col]\n",
    "            # Handle unseen labels by mapping to a default\n",
    "            input_df[col] = input_df[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "            input_df[col] = le.transform(input_df[col]).astype(np.int8)\n",
    "\n",
    "    # Ensure all expected features are present\n",
    "    expected_features = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', \n",
    "                        'Age_Mons', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', \n",
    "                        'Who completed the test']\n",
    "    for feature in expected_features:\n",
    "        if feature not in input_df.columns:\n",
    "            input_df[feature] = 0  # Default value for missing features\n",
    "\n",
    "    # Reorder columns to match training data\n",
    "    input_df = input_df[expected_features]\n",
    "\n",
    "    # Scale the features\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "    return input_scaled\n",
    "\n",
    "# Define function to predict probabilities\n",
    "def predict_autism_proba(input_data, model, le_dict, scaler):\n",
    "    # Preprocess the input\n",
    "    input_scaled = preprocess_input(input_data, le_dict, scaler)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    proba = model.predict_proba(input_scaled)\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        'No Autism (Prob)': proba[:, 0],\n",
    "        'Autism (Prob)': proba[:, 1]\n",
    "    })\n",
    "    return result\n",
    "\n",
    "sample_input = {\n",
    "    'A1': 0, 'A2': 0, 'A3': 0, 'A4': 0, 'A5': 0,\n",
    "    'A6': 0, 'A7': 1, 'A8': 0, 'A9': 0, 'A10': 1,\n",
    "    'Age_Mons': 36,\n",
    "    'Sex': 'm',\n",
    "    'Ethnicity': 'asian',\n",
    "    'Jaundice': 'no',\n",
    "    'Family_mem_with_ASD': 'no',\n",
    "    'Who completed the test': 'family member'\n",
    "}\n",
    "\n",
    "# Predict probabilities for the sample input\n",
    "try:\n",
    "    predictions = predict_autism_proba(sample_input, best_rf, le_dict, scaler)\n",
    "    logger.info(\"Prediction completed successfully\")\n",
    "    print(\"\\nPrediction Probabilities:\")\n",
    "    print(predictions)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during prediction: {str(e)}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8083703f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loaded LabelEncoder mappings, scaler, and RandomForest model\n",
      "INFO:__main__:Prediction completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Probabilities:\n",
      "   No Autism (Prob)  Autism (Prob)\n",
      "0              0.03           0.97\n"
     ]
    }
   ],
   "source": [
    "# Load LabelEncoder mappings, scaler, and model\n",
    "try:\n",
    "    le_dict = joblib.load('autism_label_encoders.pkl')\n",
    "    scaler = joblib.load('autism_scaler.pkl')\n",
    "    best_rf = joblib.load('autism_rf_model.pkl')\n",
    "    logger.info(\"Loaded LabelEncoder mappings, scaler, and RandomForest model\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"Error loading files: {str(e)}\")\n",
    "    raise e\n",
    "\n",
    "# Define function to preprocess input data\n",
    "def preprocess_input(input_data, le_dict, scaler):\n",
    "    # Convert input to DataFrame if it's a dictionary\n",
    "    if isinstance(input_data, dict):\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "    else:\n",
    "        input_df = input_data.copy()\n",
    "\n",
    "    # Convert Age_Mons to years\n",
    "    if 'Age_Mons' in input_df.columns:\n",
    "        input_df['Age_Mons'] = (input_df['Age_Mons'] / 12).astype(int)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test']\n",
    "    for col in categorical_cols:\n",
    "        if col in input_df.columns:\n",
    "            le = le_dict[col]\n",
    "            # Handle unseen labels by mapping to a default\n",
    "            input_df[col] = input_df[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "            input_df[col] = le.transform(input_df[col]).astype(np.int8)\n",
    "\n",
    "    # Ensure all expected features are present\n",
    "    expected_features = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', \n",
    "                        'Age_Mons', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', \n",
    "                        'Who completed the test']\n",
    "    for feature in expected_features:\n",
    "        if feature not in input_df.columns:\n",
    "            input_df[feature] = 0  # Default value for missing features\n",
    "\n",
    "    # Reorder columns to match training data\n",
    "    input_df = input_df[expected_features]\n",
    "\n",
    "    # Scale the features\n",
    "    input_scaled = scaler.transform(input_df)\n",
    "    return input_scaled\n",
    "\n",
    "# Define function to predict probabilities\n",
    "def predict_autism_proba(input_data, model, le_dict, scaler):\n",
    "    # Preprocess the input\n",
    "    input_scaled = preprocess_input(input_data, le_dict, scaler)\n",
    "    \n",
    "    # Predict probabilities\n",
    "    proba = model.predict_proba(input_scaled)\n",
    "    \n",
    "    # Create result DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        'No Autism (Prob)': proba[:, 0],\n",
    "        'Autism (Prob)': proba[:, 1]\n",
    "    })\n",
    "    return result\n",
    "\n",
    "sample_input = {\n",
    "    'A1': 1, 'A2': 1, 'A3': 0, 'A4': 0, 'A5': 1, \n",
    "    'A6': 1, 'A7': 0, 'A8': 1, 'A9': 0, 'A10': 1,\n",
    "    'Age_Mons': 24,  # Age in months\n",
    "    'Sex': 'm',  # 'm' or 'f'\n",
    "    'Ethnicity': 'White European',\n",
    "    'Jaundice': 'yes',  # 'yes' or 'no'\n",
    "    'Family_mem_with_ASD': 'no',  # 'yes' or 'no'\n",
    "    'Who completed the test': 'Parent'\n",
    "}\n",
    "# Predict probabilities for the sample input\n",
    "try:\n",
    "    predictions = predict_autism_proba(sample_input, best_rf, le_dict, scaler)\n",
    "    logger.info(\"Prediction completed successfully\")\n",
    "    print(\"\\nPrediction Probabilities:\")\n",
    "    print(predictions)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during prediction: {str(e)}\")\n",
    "    raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
