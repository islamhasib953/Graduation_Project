{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02940a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95428dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 27 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Age                     2392 non-null   int64  \n",
      " 1   Gender                  2392 non-null   int64  \n",
      " 2   Ethnicity               2392 non-null   int64  \n",
      " 3   EducationLevel          2392 non-null   int64  \n",
      " 4   BMI                     2392 non-null   float64\n",
      " 5   Smoking                 2392 non-null   int64  \n",
      " 6   PhysicalActivity        2392 non-null   float64\n",
      " 7   DietQuality             2392 non-null   float64\n",
      " 8   SleepQuality            2392 non-null   float64\n",
      " 9   PollutionExposure       2392 non-null   float64\n",
      " 10  PollenExposure          2392 non-null   float64\n",
      " 11  DustExposure            2392 non-null   float64\n",
      " 12  PetAllergy              2392 non-null   int64  \n",
      " 13  FamilyHistoryAsthma     2392 non-null   int64  \n",
      " 14  HistoryOfAllergies      2392 non-null   int64  \n",
      " 15  Eczema                  2392 non-null   int64  \n",
      " 16  HayFever                2392 non-null   int64  \n",
      " 17  GastroesophagealReflux  2392 non-null   int64  \n",
      " 18  LungFunctionFEV1        2392 non-null   float64\n",
      " 19  LungFunctionFVC         2392 non-null   float64\n",
      " 20  Wheezing                2392 non-null   int64  \n",
      " 21  ShortnessOfBreath       2392 non-null   int64  \n",
      " 22  ChestTightness          2392 non-null   int64  \n",
      " 23  Coughing                2392 non-null   int64  \n",
      " 24  NighttimeSymptoms       2392 non-null   int64  \n",
      " 25  ExerciseInduced         2392 non-null   int64  \n",
      " 26  Diagnosis               2392 non-null   int64  \n",
      "dtypes: float64(9), int64(18)\n",
      "memory usage: 504.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age\n",
       "51    47\n",
       "12    45\n",
       "27    43\n",
       "57    42\n",
       "22    40\n",
       "      ..\n",
       "52    24\n",
       "68    23\n",
       "30    23\n",
       "55    22\n",
       "9     21\n",
       "Name: count, Length: 75, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# تحميل الـ dataset\n",
    "df = pd.read_csv('./asthma_disease_data.csv')\n",
    "df.head()\n",
    "\n",
    "# إزالة الأعمدة الغير لازمة\n",
    "df.drop('PatientID', axis=1, inplace=True)\n",
    "df.drop('DoctorInCharge', axis=1, inplace=True)\n",
    "\n",
    "# التحقق من البيانات\n",
    "df.columns\n",
    "df.shape\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "df.duplicated().sum()\n",
    "df.dtypes\n",
    "df.describe()\n",
    "df['Age'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3201ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    2268\n",
       "1     124\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# تقريب القيم زي ما عملت\n",
    "df['BMI'] = df['BMI'].round(2)\n",
    "float_columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "                          'PollutionExposure', 'PollenExposure', 'DustExposure']\n",
    "for col in float_columns_to_round:\n",
    "    df[col] = df[col].round(0).astype(int)\n",
    "df['LungFunctionFEV1'] = df['LungFunctionFEV1'].round(1)\n",
    "df['LungFunctionFVC'] = df['LungFunctionFVC'].round(1)\n",
    "\n",
    "# التحقق من البيانات بعد التقريب\n",
    "df[float_columns_to_round]\n",
    "df[['LungFunctionFEV1', 'LungFunctionFVC']]\n",
    "df.shape\n",
    "df.dtypes\n",
    "df['Diagnosis'].value_counts()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a3bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X = df.drop(columns=['Diagnosis'])  # Features\n",
    "y = df['Diagnosis']  # Target variable (Diagnosis)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "df_resampled['Diagnosis'] = y_resampled\n",
    "df_resampled.shape\n",
    "df_resampled['Diagnosis'].value_counts()\n",
    "\n",
    "# تحديد الـ features والـ target بعد SMOTE\n",
    "X = df_resampled.drop(columns=[\"Diagnosis\"])\n",
    "y = df_resampled[\"Diagnosis\"]\n",
    "\n",
    "# تقسيم البيانات\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1215f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (3628, 26), Test set size: (908, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Future Line\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Future Line\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Metrics:\n",
      "\n",
      "                 Model  Accuracy  Precision   Recall  F1 Score        Confusion Matrix  ROC AUC\n",
      "         Random Forest  0.971366   0.975556 0.966960  0.971239  [[443, 11], [15, 439]] 0.991490\n",
      "   Logistic Regression  0.874449   0.867965 0.883260  0.875546  [[393, 61], [53, 401]] 0.933668\n",
      "Support Vector Machine  0.805066   0.771037 0.867841  0.816580 [[337, 117], [60, 394]] 0.883100\n",
      "   K-Nearest Neighbors  0.795154   0.710692 0.995595  0.829358  [[270, 184], [2, 452]] 0.932916\n",
      "     Gradient Boosting  0.922907   0.906780 0.942731  0.924406  [[410, 44], [26, 428]] 0.974184\n",
      "              AdaBoost  0.886564   0.860370 0.922907  0.890542  [[386, 68], [35, 419]] 0.948068\n",
      "        Neural Network  0.932819   0.905155 0.966960  0.935037  [[408, 46], [15, 439]] 0.968576\n",
      "\n",
      "Random Forest Model Performance (Default Parameters):\n",
      "Accuracy: 0.966960\n",
      "Precision: 0.969027\n",
      "Recall: 0.964758\n",
      "F1 Score: 0.966887\n",
      "ROC AUC Score: 0.991510\n",
      "Confusion Matrix:\n",
      "[[440  14]\n",
      " [ 16 438]]\n"
     ]
    }
   ],
   "source": [
    "# تدريب الـ scaler على الأعمدة الرقمية بس\n",
    "numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# طباعة حجم البيانات\n",
    "print(f\"Training set size: {X_train.shape}, Test set size: {X_test.shape}\")\n",
    "\n",
    "# تعريف دالة تقييم الموديلات\n",
    "\n",
    "\n",
    "def model_performance_evaluation(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates models and prints their performance metrics in a tabular format.\n",
    "\n",
    "    Parameters:\n",
    "    - models (dict): A dictionary of model names and the corresponding model object.\n",
    "    - X_train (DataFrame): The training features.\n",
    "    - y_train (Series): The target variable for training.\n",
    "    - X_test (DataFrame): The testing features.\n",
    "    - y_test (Series): The target variable for testing.\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints a table of performance metrics.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        except AttributeError:\n",
    "            roc_auc = 'N/A'\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'Confusion Matrix': conf_matrix.tolist(),\n",
    "            'ROC AUC': roc_auc\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"Model Performance Metrics:\\n\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    return results_df\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Support Vector Machine': SVC(probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Neural Network': MLPClassifier(max_iter=500)\n",
    "}\n",
    "\n",
    "# Call the evaluation function\n",
    "model_performance_evaluation(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Initialize and train Random Forest model with default parameters\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]  # For ROC AUC calculation\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"\\nRandom Forest Model Performance (Default Parameters):\")\n",
    "print(f\"Accuracy: {accuracy:.6f}\")\n",
    "print(f\"Precision: {precision:.6f}\")\n",
    "print(f\"Recall: {recall:.6f}\")\n",
    "print(f\"F1 Score: {f1:.6f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.6f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "# # حفظ الموديل والـ scaler\n",
    "# joblib.dump(rf, 'ml_service/models/asthma/RandomForest_Asthma-model.pkl')\n",
    "# joblib.dump(scaler, 'ml_service/models/asthma/scaler.pkl')\n",
    "\n",
    "# print(\"Model saved to ml_service/models/asthma/RandomForest_Asthma-model.pkl\")\n",
    "# print(\"Scaler saved to ml_service/models/asthma/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79f51f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age' 'Gender' 'Ethnicity' 'EducationLevel' 'BMI' 'Smoking'\n",
      " 'PhysicalActivity' 'DietQuality' 'SleepQuality' 'PollutionExposure'\n",
      " 'PollenExposure' 'DustExposure' 'PetAllergy' 'FamilyHistoryAsthma'\n",
      " 'HistoryOfAllergies' 'Eczema' 'HayFever' 'GastroesophagealReflux'\n",
      " 'LungFunctionFEV1' 'LungFunctionFVC' 'Wheezing' 'ShortnessOfBreath'\n",
      " 'ChestTightness' 'Coughing' 'NighttimeSymptoms' 'ExerciseInduced']\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f6dabb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Asthma' predictions: 452\n",
      "Number of 'No Asthma' predictions: 456\n",
      "Total predictions: 908\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Step 1: Make predictions on the test set using the Random Forest model\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Step 2: Count the number of \"Asthma\" (1) and \"No Asthma\" (0) predictions\n",
    "prediction_counts = Counter(predictions)\n",
    "\n",
    "# Step 3: Output the counts\n",
    "asthma_count = prediction_counts[1]\n",
    "no_asthma_count = prediction_counts[0]\n",
    "\n",
    "print(f\"Number of 'Asthma' predictions: {asthma_count}\")\n",
    "print(f\"Number of 'No Asthma' predictions: {no_asthma_count}\")\n",
    "print(f\"Total predictions: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9c37b",
   "metadata": {},
   "source": [
    "RandomForest_Asthma-model_IslV.pkl asthma-scaler_IslV.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18cb7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Asthma Diagnosis: No Asthma\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the trained model and scaler\n",
    "rf = joblib.load('RandomForest_Asthma-model_IslV.pkl')\n",
    "scaler = joblib.load('asthma-scaler_IslV.pkl')\n",
    "\n",
    "# Step 1: Provide new raw input data (before scaling)\n",
    "# The input must match ALL feature columns used in training, in the correct order\n",
    "columns = [\n",
    "    'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI', 'Smoking', \n",
    "    'PhysicalActivity', 'DietQuality', 'SleepQuality', 'PollutionExposure', \n",
    "    'PollenExposure', 'DustExposure', 'PetAllergy', 'FamilyHistoryAsthma', \n",
    "    'HistoryOfAllergies', 'Eczema', 'HayFever', 'GastroesophagealReflux', \n",
    "    'LungFunctionFEV1', 'LungFunctionFVC', 'Wheezing', 'ShortnessOfBreath', \n",
    "    'ChestTightness', 'Coughing', 'NighttimeSymptoms', 'ExerciseInduced'\n",
    "]\n",
    "\n",
    "# Input data from the provided row (excluding Diagnosis)\n",
    "new_data = np.array([[\n",
    "    54,                   # Age\n",
    "    0,                    # Gender\n",
    "    3,                    # Ethnicity\n",
    "    2,                    # EducationLevel\n",
    "    37.07955993135331,    # BMI\n",
    "    0,                    # Smoking\n",
    "    4.735168554645618,    # PhysicalActivity\n",
    "    8.214064158947492,    # DietQuality\n",
    "    7.4835206038697315,   # SleepQuality\n",
    "    2.794846705391174,    # PollutionExposure\n",
    "    3.0551388024739334,   # PollenExposure\n",
    "    9.484013332832276,    # DustExposure\n",
    "    0,                    # PetAllergy\n",
    "    0,                    # FamilyHistoryAsthma\n",
    "    0,                    # HistoryOfAllergies\n",
    "    0,                    # Eczema\n",
    "    1,                    # HayFever\n",
    "    0,                    # GastroesophagealReflux\n",
    "    1.6859615519953677,   # LungFunctionFEV1\n",
    "    3.3468766308464106,   # LungFunctionFVC\n",
    "    1,                    # Wheezing\n",
    "    0,                    # ShortnessOfBreath\n",
    "    1,                    # ChestTightness\n",
    "    1,                    # Coughing\n",
    "    0,                    # NighttimeSymptoms\n",
    "    1                     # ExerciseInduced\n",
    "]])\n",
    "\n",
    "# Step 2: Create a DataFrame with the same column names as used in training\n",
    "new_data_df = pd.DataFrame(new_data, columns=columns)\n",
    "\n",
    "# Step 3: Apply the same preprocessing as in training\n",
    "# Round BMI to 2 decimal places and LungFunction columns to 1 decimal place\n",
    "new_data_df['BMI'] = new_data_df['BMI'].round(2)\n",
    "new_data_df['LungFunctionFEV1'] = new_data_df['LungFunctionFEV1'].round(1)\n",
    "new_data_df['LungFunctionFVC'] = new_data_df['LungFunctionFVC'].round(1)\n",
    "\n",
    "# Round PhysicalActivity, DietQuality, SleepQuality, PollutionExposure, PollenExposure, DustExposure to integers\n",
    "float_columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality', \n",
    "                          'PollutionExposure', 'PollenExposure', 'DustExposure']\n",
    "for col in float_columns_to_round:\n",
    "    new_data_df[col] = new_data_df[col].round(0).astype(int)\n",
    "\n",
    "# Step 4: Scale only the specified numerical columns (BMI, LungFunctionFEV1, LungFunctionFVC)\n",
    "numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']\n",
    "new_data_df[numerical_cols] = scaler.transform(new_data_df[numerical_cols])\n",
    "\n",
    "# Step 5: Predict asthma diagnosis\n",
    "asthma_predict = rf.predict(new_data_df)\n",
    "\n",
    "# Step 6: Output the prediction\n",
    "print(f\"Predicted Asthma Diagnosis: {'Asthma' if asthma_predict[0] == 1 else 'No Asthma'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c497dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Adjusted Random Forest Performance ===\n",
      "0.9669603524229075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       454\n",
      "           1       0.92      0.94      0.93       454\n",
      "\n",
      "    accuracy                           0.93       908\n",
      "   macro avg       0.93      0.93      0.93       908\n",
      "weighted avg       0.93      0.93      0.93       908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Retrain the model with adjusted hyperparameters\n",
    "rf_adjusted = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=10,           # Limit tree depth\n",
    "    min_samples_split=10,   # Require more samples per split\n",
    "    min_samples_leaf=5,     # Require more samples per leaf\n",
    "    class_weight='balanced' # Balance class weights\n",
    ")\n",
    "\n",
    "# Fit the model on the training data (from the original code)\n",
    "# Assuming X_train, y_train are available from the original split\n",
    "rf_adjusted.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_adjusted = rf_adjusted.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"\\n=== Adjusted Random Forest Performance ===\")\n",
    "print(accuracy)\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# # Save the adjusted model\n",
    "# joblib.dump(rf_adjusted, 'RandomForest_Asthma-model_adjusted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee1288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Adjusted Random Forest Performance ===\n",
      "Accuracy: 0.9306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       454\n",
      "           1       0.92      0.94      0.93       454\n",
      "\n",
      "    accuracy                           0.93       908\n",
      "   macro avg       0.93      0.93      0.93       908\n",
      "weighted avg       0.93      0.93      0.93       908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Apply StandardScaler to numerical columns (BMI, LungFunctionFEV1, LungFunctionFVC)\n",
    "numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Step 2: Retrain the model with adjusted hyperparameters\n",
    "rf_adjusted = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=10,           # Limit tree depth\n",
    "    min_samples_split=10,   # Require more samples per split\n",
    "    min_samples_leaf=5,     # Require more samples per leaf\n",
    "    class_weight='balanced' # Balance class weights\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_adjusted.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate on the test set\n",
    "y_pred_adjusted = rf_adjusted.predict(X_test)\n",
    "\n",
    "# Step 4: Calculate accuracy and print performance\n",
    "accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "print(\"\\n=== Adjusted Random Forest Performance ===\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f78f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Save the adjusted model and scaler\n",
    "# joblib.dump(rf_adjusted, 'RandomForest_Asthma-model_adjusted.pkl')\n",
    "# joblib.dump(scaler, 'scaler_adjusted.pkl')\n",
    "# print(\"Adjusted model saved to ml_service/models/asthma/RandomForest_Asthma-model_adjusted.pkl\")\n",
    "# print(\"Adjusted scaler saved to ml_service/models/asthma/scaler_adjusted.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c09475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Asthma Diagnosis: No Asthma\n",
      "Probability of 'No Asthma' (0): 0.9323\n",
      "Probability of 'Asthma' (1): 0.0677\n"
     ]
    }
   ],
   "source": [
    "# Load the adjusted model and scaler (saved from part 1)\n",
    "rf = joblib.load('RandomForest_Asthma-model_adjusted.pkl')\n",
    "scaler = joblib.load('scaler_adjusted.pkl')\n",
    "\n",
    "# Step 1: Provide new raw input data (before scaling)\n",
    "# The input must match ALL feature columns used in training, in the correct order\n",
    "columns = [\n",
    "    'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI', 'Smoking', \n",
    "    'PhysicalActivity', 'DietQuality', 'SleepQuality', 'PollutionExposure', \n",
    "    'PollenExposure', 'DustExposure', 'PetAllergy', 'FamilyHistoryAsthma', \n",
    "    'HistoryOfAllergies', 'Eczema', 'HayFever', 'GastroesophagealReflux', \n",
    "    'LungFunctionFEV1', 'LungFunctionFVC', 'Wheezing', 'ShortnessOfBreath', \n",
    "    'ChestTightness', 'Coughing', 'NighttimeSymptoms', 'ExerciseInduced'\n",
    "]\n",
    "\n",
    "# Step 1: Provide new raw input data (before scaling)\n",
    "# The input must match ALL feature columns used in training, in the correct order\n",
    "new_data = np.array([[\n",
    "    35,                   # Age\n",
    "    1,                    # Gender\n",
    "    0,                    # Ethnicity\n",
    "    2,                    # EducationLevel\n",
    "    27.5,                 # BMI\n",
    "    1,                    # Smoking\n",
    "    3.5,                  # PhysicalActivity\n",
    "    5.0,                  # DietQuality\n",
    "    6.0,                  # SleepQuality\n",
    "    8.0,                  # PollutionExposure\n",
    "    7.5,                  # PollenExposure\n",
    "    6.5,                  # DustExposure\n",
    "    1,                    # PetAllergy\n",
    "    1,                    # FamilyHistoryAsthma\n",
    "    1,                    # HistoryOfAllergies\n",
    "    0,                    # Eczema\n",
    "    1,                    # HayFever\n",
    "    0,                    # GastroesophagealReflux\n",
    "    2.1,                  # LungFunctionFEV1\n",
    "    3.8,                  # LungFunctionFVC\n",
    "    1,                    # Wheezing\n",
    "    1,                    # ShortnessOfBreath\n",
    "    1,                    # ChestTightness\n",
    "    1,                    # Coughing\n",
    "    1,                    # NighttimeSymptoms\n",
    "    1                     # ExerciseInduced\n",
    "]])\n",
    "\n",
    "# Step 2: Create a DataFrame with the same column names as used in training\n",
    "new_data_df = pd.DataFrame(new_data, columns=columns)\n",
    "\n",
    "# Step 3: Apply the same preprocessing as in training\n",
    "# Round BMI to 2 decimal places and LungFunction columns to 1 decimal place\n",
    "new_data_df['BMI'] = new_data_df['BMI'].round(2)\n",
    "new_data_df['LungFunctionFEV1'] = new_data_df['LungFunctionFEV1'].round(1)\n",
    "new_data_df['LungFunctionFVC'] = new_data_df['LungFunctionFVC'].round(1)\n",
    "\n",
    "# Round PhysicalActivity, DietQuality, SleepQuality, PollutionExposure, PollenExposure, DustExposure to integers\n",
    "float_columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality', \n",
    "                          'PollutionExposure', 'PollenExposure', 'DustExposure']\n",
    "for col in float_columns_to_round:\n",
    "    new_data_df[col] = new_data_df[col].round(0).astype(int)\n",
    "\n",
    "# Step 4: Scale only the specified numerical columns (BMI, LungFunctionFEV1, LungFunctionFVC)\n",
    "numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']\n",
    "new_data_df[numerical_cols] = scaler.transform(new_data_df[numerical_cols])\n",
    "\n",
    "# Step 5: Predict asthma diagnosis with the adjusted model\n",
    "asthma_predict = rf_adjusted.predict(new_data_df)\n",
    "\n",
    "# Step 6: Output the prediction and probabilities for better insight\n",
    "probabilities = rf_adjusted.predict_proba(new_data_df)\n",
    "print(f\"Predicted Asthma Diagnosis: {'Asthma' if asthma_predict[0] == 1 else 'No Asthma'}\")\n",
    "print(f\"Probability of 'No Asthma' (0): {probabilities[0][0]:.4f}\")\n",
    "print(f\"Probability of 'Asthma' (1): {probabilities[0][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fd5e811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 0:\n",
      "Predicted Asthma Diagnosis: No Asthma\n",
      "Probability of 'No Asthma' (0): 0.8095\n",
      "Probability of 'Asthma' (1): 0.1905\n",
      "\n",
      "Sample 1:\n",
      "Predicted Asthma Diagnosis: Asthma\n",
      "Probability of 'No Asthma' (0): 0.4975\n",
      "Probability of 'Asthma' (1): 0.5025\n",
      "\n",
      "Sample 2:\n",
      "Predicted Asthma Diagnosis: No Asthma\n",
      "Probability of 'No Asthma' (0): 0.7208\n",
      "Probability of 'Asthma' (1): 0.2792\n",
      "\n",
      "Sample 3:\n",
      "Predicted Asthma Diagnosis: No Asthma\n",
      "Probability of 'No Asthma' (0): 0.8755\n",
      "Probability of 'Asthma' (1): 0.1245\n"
     ]
    }
   ],
   "source": [
    "# Define multiple samples\n",
    "samples = [\n",
    "    [63, 0, 1, 0, 15.848744398517509, 0, 0.8944483090233335, 5.488695584993768, 8.701002733591553, 7.388480566727442, 2.8555777852179687, 0.9743393830919789, 1, 1, 0, 0, 0, 0, 1.3690511997873338, 4.9412056608744575, 0, 0, 1, 0, 0, 1],  # Sample 0\n",
    "    [77, 1, 0, 3, 33.15135515728724, 0, 8.369617599681602, 7.755179940672062, 5.851264635104737, 6.431191150460654, 1.6294869905086307, 1.9071972016434435, 0, 0, 0, 0, 0, 0, 1.2925224430501925, 3.7143834873086083, 1, 1, 0, 1, 1, 1],  # Sample 1\n",
    "    [9, 1, 3, 1, 34.96946962586112, 0, 8.293475319059786, 1.3172863614250807, 6.960847232709893, 1.6742376846785867, 9.624349757689508, 9.94985613405871, 0, 1, 0, 0, 1, 1, 2.289334213132939, 2.9836863482330322, 1, 0, 1, 1, 0, 1],   # Sample 2\n",
    "    [42, 1, 0, 3, 16.224029068610847, 0, 3.426900354482143, 4.134466546914889, 6.687361221911186, 2.4065001334941485, 0.9461358071670567, 7.974179903908956, 1, 0, 0, 0, 0, 0, 3.7790825828241976, 4.811819957956029, 1, 1, 0, 1, 1, 0]   # Sample 3\n",
    "]\n",
    "\n",
    "# Convert samples to numpy array\n",
    "new_data = np.array(samples)\n",
    "\n",
    "# Create a DataFrame with the same column names as used in training\n",
    "new_data_df = pd.DataFrame(new_data, columns=columns)\n",
    "\n",
    "# Apply the same preprocessing as in training\n",
    "# Round BMI to 2 decimal places and LungFunction columns to 1 decimal place\n",
    "new_data_df['BMI'] = new_data_df['BMI'].round(2)\n",
    "new_data_df['LungFunctionFEV1'] = new_data_df['LungFunctionFEV1'].round(1)\n",
    "new_data_df['LungFunctionFVC'] = new_data_df['LungFunctionFVC'].round(1)\n",
    "\n",
    "# Round PhysicalActivity, DietQuality, SleepQuality, PollutionExposure, PollenExposure, DustExposure to integers\n",
    "float_columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality',\n",
    "                          'PollutionExposure', 'PollenExposure', 'DustExposure']\n",
    "for col in float_columns_to_round:\n",
    "    new_data_df[col] = new_data_df[col].round(0).astype(int)\n",
    "\n",
    "# Scale only the specified numerical columns (BMI, LungFunctionFEV1, LungFunctionFVC)\n",
    "numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']\n",
    "new_data_df[numerical_cols] = scaler.transform(new_data_df[numerical_cols])\n",
    "\n",
    "# Predict asthma diagnosis for all samples\n",
    "asthma_predictions = rf.predict(new_data_df)\n",
    "probabilities = rf.predict_proba(new_data_df)\n",
    "\n",
    "# Output predictions and probabilities for each sample\n",
    "for i, (pred, prob) in enumerate(zip(asthma_predictions, probabilities)):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Predicted Asthma Diagnosis: {'Asthma' if pred == 1 else 'No Asthma'}\")\n",
    "    print(f\"Probability of 'No Asthma' (0): {prob[0]:.4f}\")\n",
    "    print(f\"Probability of 'Asthma' (1): {prob[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
