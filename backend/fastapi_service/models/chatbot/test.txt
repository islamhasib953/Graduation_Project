
from typing import Dict, Any
import pandas as pd
import joblib
import random
import json
import pickle
import numpy as np
from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import speech_recognition as sr
from gtts import gTTS
import nltk
from nltk.stem import WordNetLemmatizer
import tensorflow as tf
import base64
import io
from src.services.model_manager import ModelManager
import logging

nltk.download('wordnet')
nltk.download('punkt')

app = FastAPI(title="Disease Prediction API")

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for input validation


class AutismInput(BaseModel):
    A1: int
    A2: int
    A3: int
    A4: int
    A5: int
    A6: int
    A7: int
    A8: int
    A9: int
    A10: int
    Age_Mons: int
    Sex: str
    Ethnicity: str
    Jaundice: str
    Family_mem_with_ASD: str
    Who_completed_the_test: str


class AsthmaInput(BaseModel):
    Age: int
    Gender: int
    Ethnicity: int
    EducationLevel: int
    BMI: float
    Smoking: int
    PhysicalActivity: float
    DietQuality: float
    SleepQuality: float
    PollutionExposure: float
    PollenExposure: float
    DustExposure: float
    PetAllergy: int
    FamilyHistoryAsthma: int
    HistoryOfAllergies: int
    Eczema: int
    HayFever: int
    GastroesophagealReflux: int
    LungFunctionFEV1: float
    LungFunctionFVC: float
    Wheezing: int
    ShortnessOfBreath: int
    ChestTightness: int
    Coughing: int
    NighttimeSymptoms: int
    ExerciseInduced: int


class StrokeInput(BaseModel):
    gender: str
    age: float
    hypertension: int
    heart_disease: int
    ever_married: str
    work_type: str
    Residence_type: str
    avg_glucose_level: float
    bmi: float
    smoking_status: str


class ChatbotInput(BaseModel):
    msg: str


# Error messages dictionary
error_messages = {
    "no_message": "No message provided. Please enter a message.",
    "speech_recognition_error": "Unable to recognize speech. Please try again.",
    "speech_recognition_service_error": "Speech recognition service error. Please check your internet connection.",
    "general_error": "Sorry, I didn't understand that, please try again in appropriate sentence or questions :).",
    "file_format_error": "File must be in WAV format."
}

# Model managers
model_managers = {}
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


@app.on_event("startup")
async def startup_event():
    try:
        model_managers["asthma"] = ModelManager("asthma")
        model_managers["autism"] = ModelManager("autism")
        model_managers["stroke"] = ModelManager("stroke")
        model_managers["chatbot"] = ModelManager("chatbot")
        logger.info("Model managers initialized successfully")
    except Exception as e:
        logger.error(f"Error initializing model managers: {str(e)}")
        raise

# Existing endpoints


@app.post("/predict/asthma")
async def predict_asthma(input_data: AsthmaInput):
    try:
        model_manager = model_managers["asthma"]
        prediction = model_manager.predict(input_data.dict())
        return prediction
    except Exception as e:
        logger.error(f"Error during prediction for asthma: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/autism")
async def predict_autism(input_data: AutismInput):
    try:
        model_manager = model_managers["autism"]
        prediction = model_manager.predict(input_data.dict())
        return prediction
    except Exception as e:
        logger.error(f"Error during prediction for autism: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/stroke")
async def predict_stroke(input_data: StrokeInput):
    try:
        model_manager = model_managers["stroke"]
        prediction = model_manager.predict(input_data.dict())
        return prediction
    except Exception as e:
        logger.error(f"Error during prediction for stroke: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Chatbot endpoints


@app.post("/medi_text")
async def process_medi_message(user_message: ChatbotInput):
    try:
        text_message = user_message.msg.lower()
        if not text_message:
            return JSONResponse(content={"text_response": error_messages["no_message"]}, status_code=400)
        model_manager = model_managers["chatbot"]
        prediction = model_manager.predict({"msg": text_message})
        return prediction
    except Exception as e:
        logger.error(f"Error during text prediction: {str(e)}")
        return JSONResponse(content={"text_response": error_messages["general_error"]}, status_code=500)


@app.post("/medi_voice")
async def process_medi_message(file: UploadFile = File(...)):
    try:
        if file.filename.endswith('.wav'):
            audio_data = await file.read()
            recognizer = sr.Recognizer()
            with io.BytesIO(audio_data) as f:
                audio = sr.AudioFile(f)
                with audio as source:
                    audio_data = recognizer.record(source)
            text_message = recognizer.recognize_google(
                audio_data, language='en').lower()
            if not text_message:
                return JSONResponse(content={"text_response": error_messages["no_message"]}, status_code=400)
            input_data = {"msg": text_message}
            model_manager = model_managers["chatbot"]
            prediction = model_manager.predict(input_data)
            return prediction
        else:
            return JSONResponse(content={"text_response": error_messages["file_format_error"]}, status_code=400)
    except sr.UnknownValueError:
        return JSONResponse(content={"text_response": error_messages["speech_recognition_error"]}, status_code=400)
    except sr.RequestError:
        return JSONResponse(content={"text_response": error_messages["speech_recognition_service_error"]}, status_code=400)
    except Exception as e:
        logger.error(f"Error during voice prediction: {str(e)}")
        return JSONResponse(content={"text_response": error_messages["general_error"]}, status_code=500)
************************


nltk.download('wordnet')
nltk.download('punkt')


class ModelManager:
    def __init__(self, disease: str):
        self.disease = disease.lower()
        self.model = None
        self.scaler = None
        self.le_dict = None
        self.logger = logging.getLogger(__name__)
        self.lemmatizer = WordNetLemmatizer()
        self.words = None
        self.classes = None
        self.intents = None
        self.load_model_and_scaler()

    def load_model_and_scaler(self):
        try:
            if self.disease == "asthma":
                model_path = "models/asthma/RandomForest_Asthma-model_adjusted.pkl"
                scaler_path = "models/asthma/scaler_adjusted.pkl"
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(scaler_path)
            elif self.disease == "autism":
                model_path = "models/autism/autism_rf_model.pkl"
                scaler_path = "models/autism/autism_scaler.pkl"
                le_path = "models/autism/autism_label_encoders.pkl"
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(scaler_path)
                self.le_dict = joblib.load(le_path)
            elif self.disease == "stroke":
                model_path = "models/stroke/stroke_gb_model.pkl"
                scaler_path = "models/stroke/scaler_stroke.pkl"
                le_path = "models/stroke/label_encoder_stroke.pkl"
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(scaler_path)
                self.le_dict = joblib.load(le_path)
            elif self.disease == "chatbot":
                model_path = "models/chatbot/chatbot_model_v5.h5"
                self.model = tf.keras.models.load_model(
                    model_path, compile=True, safe_mode=True)
                self.words = pickle.load(
                    open("models/chatbot/words_v5.pkl", 'rb'))
                self.classes = pickle.load(
                    open("models/chatbot/classes_v5.pkl", 'rb'))
                self.intents = json.loads(
                    open("models/chatbot/intents.json").read())
                self.logger.info(
                    f"Chatbot model, words, classes, and intents loaded successfully")
            else:
                raise ValueError(f"Unsupported disease: {self.disease}")

            if self.disease in ["asthma", "autism", "stroke"]:
                self.logger.info(
                    f"Model and scaler for {self.disease} loaded successfully")
                self.logger.info(
                    f"Scaler for {self.disease} expects features: {self.scaler.feature_names_in_}")
        except Exception as e:
            self.logger.error(
                f"Error loading model or scaler for {self.disease}: {str(e)}")
            raise

    def clean_up_sentence(self, sentence):
        sentence_words = nltk.word_tokenize(sentence)
        sentence_words = [self.lemmatizer.lemmatize(
            word) for word in sentence_words]
        return sentence_words

    def bag_of_words(self, sentence):
        sentence_words = self.clean_up_sentence(sentence)
        bag = [0] * len(self.words)
        for w in sentence_words:
            for i, word in enumerate(self.words):
                if word == w:
                    bag[i] = 1
        return np.array(bag)

    def predict_class(self, sentence):
        bow = self.bag_of_words(sentence)
        res = self.model.predict(np.array([bow]))[0]
        ERROR_THRESHOLD = 0.25
        results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]
        results.sort(key=lambda x: x[1], reverse=True)
        return_list = []
        if results:
            for r in results:
                return_list.append(
                    {'intent': self.classes[r[0]], 'probability': str(r[1])})
        return return_list

    def get_response(self, intents_list):
        if not intents_list:
            return "Sorry, I didn't understand that."
        tag = intents_list[0]['intent']
        self.logger.info(f"Detected intent: {tag}")
        list_of_intents = self.intents['intents']
        result = ''
        for i in list_of_intents:
            if i['tag'] == tag:
                self.logger.info(f"Responses found: {i['responses']}")
                result = random.choice(i['responses'])
                break
        return result

    def preprocess_input(self, input_data: Dict[str, Any]) -> np.ndarray:
        try:
            df = pd.DataFrame([input_data])
            if self.disease == "asthma":
                df['BMI'] = df['BMI'].round(2)
                df['LungFunctionFEV1'] = df['LungFunctionFEV1'].round(1)
                df['LungFunctionFVC'] = df['LungFunctionFVC'].round(1)
                float_columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality',
                                          'PollutionExposure', 'PollenExposure', 'DustExposure']
                for col in float_columns_to_round:
                    df[col] = df[col].round(0).astype(int)
                numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']
                self.logger.info(
                    f"Input data before scaling: {df[numerical_cols]}")
                df[numerical_cols] = self.scaler.transform(df[numerical_cols])
                self.logger.info(f"Scaled numerical columns: {numerical_cols}")
            elif self.disease == "autism":
                if 'Who completed the test' in df.columns:
                    df['Who completed the test'] = df['Who completed the test'].replace(
                        'Parent', 'family member')
                if 'Age_Mons' in df.columns:
                    df['Age_Mons'] = (df['Age_Mons'] / 12).astype(int)
                categorical_cols = ['Sex', 'Ethnicity', 'Jaundice',
                                    'Family_mem_with_ASD', 'Who completed the test']
                for col in categorical_cols:
                    if col in df.columns:
                        le = self.le_dict[col]
                        df[col] = df[col].apply(
                            lambda x: x if x in le.classes_ else le.classes_[0])
                        df[col] = le.transform(df[col]).astype(np.int8)
                expected_features = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10',
                                     'Age_Mons', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',
                                     'Who completed the test']
                for feature in expected_features:
                    if feature not in df.columns:
                        df[feature] = 0
                df = df[expected_features]
                self.logger.info(f"Input data before scaling: {df}")
                df = self.scaler.transform(df)
                self.logger.info(f"Scaled features for autism")
            elif self.disease == "stroke":
                df['gender'] = df['gender'].replace({'Male': 0, 'Female': 1})
                for col in ['ever_married', 'smoking_status']:
                    if col in df.columns:
                        le = self.le_dict[col]
                        df[col] = df[col].apply(
                            lambda x: x if x in le.classes_ else le.classes_[0])
                        df[col] = le.transform(df[col]).astype(np.int8)
                df['work_type'] = df['work_type'].replace(
                    {'Private': 0, 'Self-employed': 1, 'Govt_job': 2, 'children': 3, 'Never_worked': 4})
                df['Residence_type'] = df['Residence_type'].replace(
                    {'Rural': 0, 'Urban': 1})
                expected_features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type',
                                     'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']
                for feature in expected_features:
                    if feature not in df.columns:
                        df[feature] = 0
                df = df[expected_features]
                self.logger.info(f"Input data before scaling: {df}")
                df = self.scaler.transform(df)
                self.logger.info(f"Scaled features for stroke")
            elif self.disease == "chatbot":
                sentence = input_data.get('msg', '')
                if not sentence:
                    raise ValueError("No message provided")
                return self.bag_of_words(sentence.lower())
            return df
        except Exception as e:
            self.logger.error(f"Error preprocessing input data: {str(e)}")
            raise

    def predict(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        try:
            X = self.preprocess_input(input_data)
            if self.disease in ["asthma", "autism", "stroke"]:
                prediction = self.model.predict(X)[0]
                probability = self.model.predict_proba(X)[0][1] if hasattr(
                    self.model, 'predict_proba') else random.uniform(0.5, 0.9)
            elif self.disease == "chatbot":
                res = self.model.predict(X)[0]
                ERROR_THRESHOLD = 0.25
                results = [[i, r]
                           for i, r in enumerate(res) if r > ERROR_THRESHOLD]
                results.sort(key=lambda x: x[1], reverse=True)
                return_list = []
                if results:
                    for r in results:
                        return_list.append(
                            {'intent': self.classes[r[0]], 'probability': str(r[1])})
                if not return_list:
                    return {
                        "user_message": input_data.get('msg', ''),
                        "text_response": "Sorry, I didn't understand that."
                    }
                tag = return_list[0]['intent']
                for i in self.intents['intents']:
                    if i['tag'] == tag:
                        response = random.choice(i['responses'])
                        break
                else:
                    response = "Sorry, I didn't understand that."
                return {
                    "user_message": input_data.get('msg', ''),
                    "text_response": response
                }
            else:
                raise ValueError(f"Unsupported disease: {self.disease}")

            if self.disease == "asthma":
                if prediction == 0 and probability > 0.7:
                    diagnosis = "No Asthma"
                elif prediction == 0 and probability <= 0.7:
                    diagnosis = "Asthma"
                    prediction = 1
                elif prediction == 1 and probability > 0.25:
                    diagnosis = "Asthma"
                elif prediction == 1 and probability < 0.25:
                    diagnosis = "No Asthma"
            elif self.disease == "autism":
                diagnosis = "ASD" if prediction == 1 else "No ASD"
            elif self.disease == "stroke":
                diagnosis = "Stroke" if prediction == 1 and probability > 0.1 else "No Stroke"

            return {
                "prediction": int(prediction),
                "probability": float(probability),
                "diagnosis": diagnosis,
                "class_predicted": diagnosis,
                "probability_note": f"Probability represents the likelihood of {self.disease.capitalize()}"
            }
        except Exception as e:
            self.logger.error(f"Error during prediction: {str(e)}")
            raise
************************

const axios = require("axios");
const FormData = require("form-data"); // Added for file upload
const fs = require("fs");
const winston = require("winston");
const httpStatusText = require("../utils/httpStatusText");
const AppError = require("../utils/appError");

const FASTAPI_URL = process.env.FASTAPI_URL || "http://localhost:8001";

// Configure logging
const logger = winston.createLogger({
  level: "info",
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [new winston.transports.Console()],
});

// Required fields for each model
const requiredFields = {
  asthma: [
    "Age",
    "Gender",
    "Ethnicity",
    "EducationLevel",
    "BMI",
    "Smoking",
    "PhysicalActivity",
    "DietQuality",
    "SleepQuality",
    "PollutionExposure",
    "PollenExposure",
    "DustExposure",
    "PetAllergy",
    "FamilyHistoryAsthma",
    "HistoryOfAllergies",
    "Eczema",
    "HayFever",
    "GastroesophagealReflux",
    "LungFunctionFEV1",
    "LungFunctionFVC",
    "Wheezing",
    "ShortnessOfBreath",
    "ChestTightness",
    "Coughing",
    "NighttimeSymptoms",
    "ExerciseInduced",
  ],
  autism: [
    "A1",
    "A2",
    "A3",
    "A4",
    "A5",
    "A6",
    "A7",
    "A8",
    "A9",
    "A10",
    "Age_Mons",
    "Sex",
    "Ethnicity",
    "Jaundice",
    "Family_mem_with_ASD",
    "Who_completed_the_test",
  ],
  stroke: [
    "gender",
    "age",
    "hypertension",
    "heart_disease",
    "ever_married",
    "work_type",
    "Residence_type",
    "avg_glucose_level",
    "bmi",
    "smoking_status",
  ],
  chatbot: ["msg"],
};

const predictDisease = async (req, res, next) => {
  try {
    const { disease } = req.params;

    // Validate disease
    if (!["asthma", "autism", "stroke", "chatbot"].includes(disease)) {
      logger.error(`Invalid disease requested: ${disease}`);
      return next(new AppError(`Invalid disease: ${disease}`, 400));
    }

    // Validate input fields
    const fields = requiredFields[disease];
    for (const field of fields) {
      if (!(field in req.body) && disease !== "chatbot") {
        logger.error(`Missing required field: ${field} for ${disease}`);
        return next(new AppError(`Missing required field: ${field}`, 400));
      }
    }

    // Log the prediction request
    logger.info(`Prediction request for ${disease}`, { input: req.body });

    // Send request to FastAPI
    let endpoint = `${FASTAPI_URL}/predict/${disease}`;
    if (disease === "chatbot") {
      if (req.file && req.file.fieldname === "audio") {
        // Handle voice input (WAV file)
        const formData = new FormData();
        formData.append("file", fs.createReadStream(req.file.path), {
          filename: req.file.originalname,
        });
        endpoint = `${FASTAPI_URL}/medi_voice`;
        const response = await axios.post(endpoint, formData, {
          headers: formData.getHeaders(),
        });
        logger.info(`Prediction successful for ${disease} (voice)`, {
          response: response.data,
        });
        return res.status(200).json({
          status: httpStatusText.SUCCESS,
          data: response.data,
        });
      } else if (req.body.msg) {
        // Handle text input
        endpoint = `${FASTAPI_URL}/medi_text`;
        const response = await axios.post(endpoint, req.body);
        logger.info(`Prediction successful for ${disease} (text)`, {
          response: response.data,
        });
        return res.status(200).json({
          status: httpStatusText.SUCCESS,
          data: response.data,
        });
      } else {
        logger.error(`No msg or audio file provided for chatbot`);
        return next(new AppError(`No message or audio file provided`, 400));
      }
    } else {
      const response = await axios.post(endpoint, req.body);
      logger.info(`Prediction successful for ${disease}`, {
        response: response.data,
      });
      return res.status(200).json({
        status: httpStatusText.SUCCESS,
        data: response.data,
      });
    }
  } catch (error) {
    logger.error(
      `Failed to get prediction for ${req.params.disease}: ${error.message}`
    );
    return next(
      new AppError(
        `Failed to get prediction: ${error.message}`,
        error.response?.status || 500
      )
    );
  }
};

module.exports = { predictDisease };