http://0.0.0.0:8001/medi_text
{
  "msg": "Hello"
}
{
    "text_response": "Sorry, I didn't understand that, please try again in appropriate sentence or questions :)."
}

(venv) m-hassib@m-hassib fastapi_service$ uvicorn src.main:app --host 0.0.0.0 --port 8001
2025-05-12 19:21:59.603475: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-05-12 19:21:59.621967: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-05-12 19:21:59.683186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-05-12 19:21:59.739375: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-05-12 19:21:59.753055: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-12 19:21:59.783708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-12 19:22:01.934930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package wordnet to /home/m-hassib/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/m-hassib/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package wordnet to /home/m-hassib/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package punkt to /home/m-hassib/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
INFO:     Started server process [43498]
INFO:     Waiting for application startup.
INFO:src.services.model_manager:Model and scaler for asthma loaded successfully
INFO:src.services.model_manager:Scaler for asthma expects features: ['BMI' 'LungFunctionFEV1' 'LungFunctionFVC']
INFO:src.services.model_manager:Model and scaler for autism loaded successfully
INFO:src.services.model_manager:Scaler for autism expects features: ['A1' 'A2' 'A3' 'A4' 'A5' 'A6' 'A7' 'A8' 'A9' 'A10' 'Age_Mons' 'Sex'
 'Ethnicity' 'Jaundice' 'Family_mem_with_ASD' 'Who completed the test']
INFO:src.services.model_manager:Model and scaler for stroke loaded successfully
INFO:src.services.model_manager:Scaler for stroke expects features: ['gender' 'age' 'hypertension' 'heart_disease' 'ever_married' 'work_type'
 'Residence_type' 'avg_glucose_level' 'bmi' 'smoking_status']
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
INFO:src.services.model_manager:Chatbot model, words, classes, and intents loaded successfully
INFO:src.main:Model managers initialized successfully
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)
ERROR:src.services.model_manager:Error during prediction: Exception encountered when calling Sequential.call().

Invalid input shape for input Tensor("sequential_1/Cast:0", shape=(32,), dtype=float32). Expected shape (None, 2361), but input has incompatible shape (32,)

Arguments received by Sequential.call():
  • inputs=tf.Tensor(shape=(32,), dtype=int64)
  • training=False
  • mask=None
ERROR:src.main:Error during text prediction: Exception encountered when calling Sequential.call().

Invalid input shape for input Tensor("sequential_1/Cast:0", shape=(32,), dtype=float32). Expected shape (None, 2361), but input has incompatible shape (32,)

Arguments received by Sequential.call():
  • inputs=tf.Tensor(shape=(32,), dtype=int64)
  • training=False
  • mask=None
INFO:     127.0.0.1:34384 - "POST /medi_text HTTP/1.1" 500 Internal Server Error
ERROR:src.services.model_manager:Error during prediction: Exception encountered when calling Sequential.call().

Invalid input shape for input Tensor("sequential_1/Cast:0", shape=(32,), dtype=float32). Expected shape (None, 2361), but input has incompatible shape (32,)

Arguments received by Sequential.call():
  • inputs=tf.Tensor(shape=(32,), dtype=int64)
  • training=False
  • mask=None
ERROR:src.main:Error during text prediction: Exception encountered when calling Sequential.call().

Invalid input shape for input Tensor("sequential_1/Cast:0", shape=(32,), dtype=float32). Expected shape (None, 2361), but input has incompatible shape (32,)

Arguments received by Sequential.call():
  • inputs=tf.Tensor(shape=(32,), dtype=int64)
  • training=False
  • mask=None
INFO:     127.0.0.1:45668 - "POST /medi_text HTTP/1.1" 500 Internal Server Error
***********************
ين المشكلة
import random
import json
import pickle
import numpy as np
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import nltk
from nltk.stem import WordNetLemmatizer
import tensorflow as tf
from src.services.model_manager import ModelManager
import logging

nltk.download('wordnet')
nltk.download('punkt')

app = FastAPI(title="Disease Prediction API")

origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models for input validation


class AutismInput(BaseModel):
    A1: int
    A2: int
    A3: int
    A4: int
    A5: int
    A6: int
    A7: int
    A8: int
    A9: int
    A10: int
    Age_Mons: int
    Sex: str
    Ethnicity: str
    Jaundice: str
    Family_mem_with_ASD: str
    Who_completed_the_test: str


class AsthmaInput(BaseModel):
    Age: int
    Gender: int
    Ethnicity: int
    EducationLevel: int
    BMI: float
    Smoking: int
    PhysicalActivity: float
    DietQuality: float
    SleepQuality: float
    PollutionExposure: float
    PollenExposure: float
    DustExposure: float
    PetAllergy: int
    FamilyHistoryAsthma: int
    HistoryOfAllergies: int
    Eczema: int
    HayFever: int
    GastroesophagealReflux: int
    LungFunctionFEV1: float
    LungFunctionFVC: float
    Wheezing: int
    ShortnessOfBreath: int
    ChestTightness: int
    Coughing: int
    NighttimeSymptoms: int
    ExerciseInduced: int


class StrokeInput(BaseModel):
    gender: str
    age: float
    hypertension: int
    heart_disease: int
    ever_married: str
    work_type: str
    Residence_type: str
    avg_glucose_level: float
    bmi: float
    smoking_status: str


class ChatbotInput(BaseModel):
    msg: str


# Error messages dictionary
error_messages = {
    "no_message": "No message provided. Please enter a message.",
    "general_error": "Sorry, I didn't understand that, please try again in appropriate sentence or questions :).",
}

# Model managers
model_managers = {}
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


@app.on_event("startup")
async def startup_event():
    try:
        model_managers["asthma"] = ModelManager("asthma")
        model_managers["autism"] = ModelManager("autism")
        model_managers["stroke"] = ModelManager("stroke")
        model_managers["chatbot"] = ModelManager("chatbot")
        logger.info("Model managers initialized successfully")
    except Exception as e:
        logger.error(f"Error initializing model managers: {str(e)}")
        raise

# Existing endpoints


@app.post("/predict/asthma")
async def predict_asthma(input_data: AsthmaInput):
    try:
        model_manager = model_managers["asthma"]
        prediction = model_manager.predict(input_data.dict())
        return prediction
    except Exception as e:
        logger.error(f"Error during prediction for asthma: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/autism")
async def predict_autism(input_data: AutismInput):
    try:
        model_manager = model_managers["autism"]
        prediction = model_manager.predict(input_data.dict())
        return prediction
    except Exception as e:
        logger.error(f"Error during prediction for autism: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/stroke")
async def predict_stroke(input_data: StrokeInput):
    try:
        model_manager = model_managers["stroke"]
        prediction = model_manager.predict(input_data.dict())
        return prediction
    except Exception as e:
        logger.error(f"Error during prediction for stroke: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# Chatbot endpoint (text only)


@app.post("/medi_text")
async def process_medi_text(user_message: ChatbotInput):
    try:
        text_message = user_message.msg.lower()
        if not text_message:
            return JSONResponse(content={"text_response": error_messages["no_message"]}, status_code=400)
        model_manager = model_managers["chatbot"]
        prediction = model_manager.predict({"msg": text_message})
        return prediction
    except Exception as e:
        logger.error(f"Error during text prediction: {str(e)}")
        return JSONResponse(content={"text_response": error_messages["general_error"]}, status_code=500)

*******************************

import joblib
import pandas as pd
import numpy as np
import logging
import random
from typing import Dict, Any
import nltk
from nltk.stem import WordNetLemmatizer
import tensorflow as tf
import json
import pickle

nltk.download('wordnet')
nltk.download('punkt')


class ModelManager:
    def __init__(self, disease: str):
        self.disease = disease.lower()
        self.model = None
        self.scaler = None
        self.le_dict = None
        self.logger = logging.getLogger(__name__)
        self.lemmatizer = WordNetLemmatizer()
        self.words = None
        self.classes = None
        self.intents = None
        self.load_model_and_scaler()

    def load_model_and_scaler(self):
        try:
            if self.disease == "asthma":
                model_path = "models/asthma/RandomForest_Asthma-model_adjusted.pkl"
                scaler_path = "models/asthma/scaler_adjusted.pkl"
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(scaler_path)
            elif self.disease == "autism":
                model_path = "models/autism/autism_rf_model.pkl"
                scaler_path = "models/autism/autism_scaler.pkl"
                le_path = "models/autism/autism_label_encoders.pkl"
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(scaler_path)
                self.le_dict = joblib.load(le_path)
            elif self.disease == "stroke":
                model_path = "models/stroke/stroke_gb_model.pkl"
                scaler_path = "models/stroke/scaler_stroke.pkl"
                le_path = "models/stroke/label_encoder_stroke.pkl"
                self.model = joblib.load(model_path)
                self.scaler = joblib.load(scaler_path)
                self.le_dict = joblib.load(le_path)
            elif self.disease == "chatbot":
                model_path = "models/chatbot/chatbot_model_v5.h5"
                self.model = tf.keras.models.load_model(
                    model_path, compile=True, safe_mode=True)
                self.words = pickle.load(
                    open("models/chatbot/words_v5.pkl", 'rb'))
                self.classes = pickle.load(
                    open("models/chatbot/classes_v5.pkl", 'rb'))
                self.intents = json.loads(
                    open("models/chatbot/intents.json").read())
                self.logger.info(
                    f"Chatbot model, words, classes, and intents loaded successfully")
            else:
                raise ValueError(f"Unsupported disease: {self.disease}")

            if self.disease in ["asthma", "autism", "stroke"]:
                self.logger.info(
                    f"Model and scaler for {self.disease} loaded successfully")
                self.logger.info(
                    f"Scaler for {self.disease} expects features: {self.scaler.feature_names_in_}")
        except Exception as e:
            self.logger.error(
                f"Error loading model or scaler for {self.disease}: {str(e)}")
            raise

    def clean_up_sentence(self, sentence):
        sentence_words = nltk.word_tokenize(sentence)
        sentence_words = [self.lemmatizer.lemmatize(
            word) for word in sentence_words]
        return sentence_words

    def bag_of_words(self, sentence):
        sentence_words = self.clean_up_sentence(sentence)
        bag = [0] * len(self.words)
        for w in sentence_words:
            for i, word in enumerate(self.words):
                if word == w:
                    bag[i] = 1
        return np.array(bag)

    def predict_class(self, sentence):
        bow = self.bag_of_words(sentence)
        res = self.model.predict(np.array([bow]))[0]
        ERROR_THRESHOLD = 0.25
        results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]
        results.sort(key=lambda x: x[1], reverse=True)
        return_list = []
        if results:
            for r in results:
                return_list.append(
                    {'intent': self.classes[r[0]], 'probability': str(r[1])})
        return return_list

    def get_response(self, intents_list):
        if not intents_list:
            return "Sorry, I didn't understand that."
        tag = intents_list[0]['intent']
        self.logger.info(f"Detected intent: {tag}")
        list_of_intents = self.intents['intents']
        result = ''
        for i in list_of_intents:
            if i['tag'] == tag:
                self.logger.info(f"Responses found: {i['responses']}")
                result = random.choice(i['responses'])
                break
        return result

    def preprocess_input(self, input_data: Dict[str, Any]) -> np.ndarray:
        try:
            df = pd.DataFrame([input_data])
            if self.disease == "asthma":
                df['BMI'] = df['BMI'].round(2)
                df['LungFunctionFEV1'] = df['LungFunctionFEV1'].round(1)
                df['LungFunctionFVC'] = df['LungFunctionFVC'].round(1)
                float_columns_to_round = ['PhysicalActivity', 'DietQuality', 'SleepQuality',
                                          'PollutionExposure', 'PollenExposure', 'DustExposure']
                for col in float_columns_to_round:
                    df[col] = df[col].round(0).astype(int)
                numerical_cols = ['BMI', 'LungFunctionFEV1', 'LungFunctionFVC']
                self.logger.info(
                    f"Input data before scaling: {df[numerical_cols]}")
                df[numerical_cols] = self.scaler.transform(df[numerical_cols])
                self.logger.info(f"Scaled numerical columns: {numerical_cols}")
            elif self.disease == "autism":
                if 'Who completed the test' in df.columns:
                    df['Who completed the test'] = df['Who completed the test'].replace(
                        'Parent', 'family member')
                if 'Age_Mons' in df.columns:
                    df['Age_Mons'] = (df['Age_Mons'] / 12).astype(int)
                categorical_cols = ['Sex', 'Ethnicity', 'Jaundice',
                                    'Family_mem_with_ASD', 'Who completed the test']
                for col in categorical_cols:
                    if col in df.columns:
                        le = self.le_dict[col]
                        df[col] = df[col].apply(
                            lambda x: x if x in le.classes_ else le.classes_[0])
                        df[col] = le.transform(df[col]).astype(np.int8)
                expected_features = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10',
                                     'Age_Mons', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',
                                     'Who completed the test']
                for feature in expected_features:
                    if feature not in df.columns:
                        df[feature] = 0
                df = df[expected_features]
                self.logger.info(f"Input data before scaling: {df}")
                df = self.scaler.transform(df)
                self.logger.info(f"Scaled features for autism")
            elif self.disease == "stroke":
                df['gender'] = df['gender'].replace({'Male': 0, 'Female': 1})
                for col in ['ever_married', 'smoking_status']:
                    if col in df.columns:
                        le = self.le_dict[col]
                        df[col] = df[col].apply(
                            lambda x: x if x in le.classes_ else le.classes_[0])
                        df[col] = le.transform(df[col]).astype(np.int8)
                df['work_type'] = df['work_type'].replace(
                    {'Private': 0, 'Self-employed': 1, 'Govt_job': 2, 'children': 3, 'Never_worked': 4})
                df['Residence_type'] = df['Residence_type'].replace(
                    {'Rural': 0, 'Urban': 1})
                expected_features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type',
                                     'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']
                for feature in expected_features:
                    if feature not in df.columns:
                        df[feature] = 0
                df = df[expected_features]
                self.logger.info(f"Input data before scaling: {df}")
                df = self.scaler.transform(df)
                self.logger.info(f"Scaled features for stroke")
            elif self.disease == "chatbot":
                sentence = input_data.get('msg', '')
                if not sentence:
                    raise ValueError("No message provided")
                return self.bag_of_words(sentence.lower())
            return df
        except Exception as e:
            self.logger.error(f"Error preprocessing input data: {str(e)}")
            raise

    def predict(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        try:
            X = self.preprocess_input(input_data)
            if self.disease in ["asthma", "autism", "stroke"]:
                prediction = self.model.predict(X)[0]
                probability = self.model.predict_proba(X)[0][1] if hasattr(
                    self.model, 'predict_proba') else random.uniform(0.5, 0.9)
            elif self.disease == "chatbot":
                res = self.model.predict(X)[0]
                ERROR_THRESHOLD = 0.25
                results = [[i, r]
                           for i, r in enumerate(res) if r > ERROR_THRESHOLD]
                results.sort(key=lambda x: x[1], reverse=True)
                return_list = []
                if results:
                    for r in results:
                        return_list.append(
                            {'intent': self.classes[r[0]], 'probability': str(r[1])})
                if not return_list:
                    return {
                        "user_message": input_data.get('msg', ''),
                        "text_response": "Sorry, I didn't understand that."
                    }
                tag = return_list[0]['intent']
                for i in self.intents['intents']:
                    if i['tag'] == tag:
                        response = random.choice(i['responses'])
                        break
                else:
                    response = "Sorry, I didn't understand that."
                return {
                    "user_message": input_data.get('msg', ''),
                    "text_response": response
                }
            else:
                raise ValueError(f"Unsupported disease: {self.disease}")

            if self.disease == "asthma":
                if prediction == 0 and probability > 0.7:
                    diagnosis = "No Asthma"
                elif prediction == 0 and probability <= 0.7:
                    diagnosis = "Asthma"
                    prediction = 1
                elif prediction == 1 and probability > 0.25:
                    diagnosis = "Asthma"
                elif prediction == 1 and probability < 0.25:
                    diagnosis = "No Asthma"
            elif self.disease == "autism":
                diagnosis = "ASD" if prediction == 1 else "No ASD"
            elif self.disease == "stroke":
                diagnosis = "Stroke" if prediction == 1 and probability > 0.1 else "No Stroke"

            return {
                "prediction": int(prediction),
                "probability": float(probability),
                "diagnosis": diagnosis,
                "class_predicted": diagnosis,
                "probability_note": f"Probability represents the likelihood of {self.disease.capitalize()}"
            }
        except Exception as e:
            self.logger.error(f"Error during prediction: {str(e)}")
            raise
****************************
http://0.0.0.0:8001/medi_text

{
  "msg": "Hello"
}

{
    "text_response": "Sorry, I didn't understand that, please try again in appropriate sentence or questions :)."
}

********************
